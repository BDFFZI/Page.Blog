# 【人工智能】特征处理

## 特征工程

有时因输入特征不够全面，仅靠现有的特征并不能完美的表达问题规则。因此，可以利用直觉，通过对原有特征的转化组合，创造出新的特征和模型参数，以增强模型的准确性。

使用特征工程的最好案例就是多项式回归模型的实现。

## 特征选择

用于训练模型的特征并不是越多越好，过多的特征可能导致过拟合。因此发生过拟合时的一种解决方法就是考虑减少输入特征，只保留一些关键特征。

## 特征缩放

(似乎使用自适应学习率（如 adam 之类）就不需要使用该方法了)

在多元线性回归中，当输入特征大小差异过大时，其生成的模型参数也会差异过大，因此在成本函数的等高线图中会呈现类似椭圆形的效果，对这种形状的函数做梯度下降速度会很慢（下降过程中部分参数出现弹跳）。此时便需要进行输入特征缩放，从而使模型参数在做梯度下降时的取值范围统一，这样可以显著加快梯度下降的速度。

注意：由于特征被缩放，因此训练得出的模型参数也是被缩放的，所以最终需要对这些参数反缩放，以得到适用于原始数据集的模型参数。

### 最大值归一化

将输入特征的最大值全部缩放到 1。

$$
x^{(i)}=\frac{x^{(i)}}{max(x)}
$$

### 均值归一化

将输入特征缩放到-1 到 1，并将中心点置于 0。

$$
x^{(i)}=\frac{x^{(i)}-average(x)}{max(x)-min(x)}
$$

### Z 分数归一化

$$
x^{(i)}=\frac{x^{(i)}-average(x)}{\sigma(x)}
$$

- $\sigma$：标准差
